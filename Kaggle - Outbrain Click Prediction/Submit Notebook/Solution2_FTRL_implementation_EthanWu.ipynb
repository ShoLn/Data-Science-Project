{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "another-hanging",
   "metadata": {},
   "source": [
    "### 讀資料&調參"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "korean-softball",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "from csv import DictReader\n",
    "from math import exp, log, sqrt\n",
    "\n",
    "# A, paths\n",
    "data_path = '...'\n",
    "train = data_path+'clicks_train.csv'               # path to training file\n",
    "test = data_path+'clicks_test.csv'                 # path to testing file\n",
    "submission = 'sub_proba.csv'  # path of to be outputted submission file\n",
    "\n",
    "# B, model\n",
    "alpha = .2  # learning rate\n",
    "beta = .1   # smoothing parameter for adaptive learning rate\n",
    "L1 = 0.1    # L1 regularization, larger value means more regularized\n",
    "L2 = 0.1     # L2 regularization, larger value means more regularized\n",
    "\n",
    "# C, feature/hash trick\n",
    "D = 2 ** 20             # number of weights to use\n",
    "\n",
    "# D, training/validation\n",
    "epoch = 1       # learn training data for N passes\n",
    "holdafter = None   # data after date N (exclusive) are used as validation\n",
    "holdout = None  # use every N training instance for holdout validation\n",
    "interaction = False     # whether to enable poly2 feature interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-success",
   "metadata": {},
   "source": [
    "### promoted_content\n",
    "* 把csv轉成prcont_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "laden-subscriber",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ad_id</th>\n",
       "      <th>document_id</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>advertiser_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6614</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>471467</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7692</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ad_id  document_id  campaign_id  advertiser_id\n",
       "0      1         6614            1              7\n",
       "1      2       471467            2              7\n",
       "2      3         7692            3              7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "pd.read_csv(data_path + \"promoted_content.csv\").head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "postal-mortgage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559583\n"
     ]
    }
   ],
   "source": [
    "with open(data_path + \"promoted_content.csv\") as infile:\n",
    "\tprcont = csv.reader(infile)\n",
    "\tprcont_header = next(prcont)[1:]#['document_id', 'campaign_id', 'advertiser_id']\n",
    "\n",
    "\tprcont_dict = {}#把csv轉乘dict格式\n",
    "\tfor ind,row in enumerate(prcont):\n",
    "\t\tprcont_dict[int(row[0])] = row[1:]\n",
    "\tprint(len(prcont_dict))\n",
    "del prcont"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-tampa",
   "metadata": {},
   "source": [
    "### Event\n",
    "* 把csv轉成event_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "simple-uncle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23120126\n"
     ]
    }
   ],
   "source": [
    "with open(data_path + \"events.csv\") as infile:\n",
    "\tevents = csv.reader(infile)\n",
    "\t#events.next()\n",
    "\tnext(events)\n",
    "\tevent_header = ['uuid', 'document_id', 'platform', 'geo_location', 'loc_country', 'loc_state', 'loc_dma']\n",
    "\tevent_dict = {}\n",
    "\tfor ind,row in enumerate(events):\n",
    "\t\ttlist = row[1:3] + row[4:6]\n",
    "\t\tloc = row[5].split('>')\n",
    "        \n",
    "        #有些國家長度不同，要補齊\n",
    "\t\tif len(loc) == 3:\n",
    "\t\t\ttlist.extend(loc[:])\n",
    "\t\telif len(loc) == 2:\n",
    "\t\t\ttlist.extend( loc[:]+[''])\n",
    "\t\telif len(loc) == 1:\n",
    "\t\t\ttlist.extend( loc[:]+['',''])\n",
    "\t\telse:\n",
    "\t\t\ttlist.append(['','',''])\t\n",
    "\t\tevent_dict[int(row[0])] = tlist[:] \n",
    "\tprint(len(event_dict))\n",
    "del events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-affiliate",
   "metadata": {},
   "source": [
    "### FTRL class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "virgin-furniture",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ftrl_proximal(object):\n",
    "    def __init__(self, alpha, beta, L1, L2, D, interaction):\n",
    "        # parameters\n",
    "        self.alpha = alpha; self.beta = beta \n",
    "        self.L1 = L1; self.L2 = L2\n",
    "\n",
    "        # feature related parameters\n",
    "        self.D = D; self.interaction = interaction\n",
    "        # model\n",
    "        self.n = [0.] * D        # n: squared sum of past gradients\n",
    "        self.z = [0.] * D        # z: weights\n",
    "        self.w = {}              # w: lazy weights\n",
    "        \n",
    "    def _indices(self, x):\n",
    "        # first yield index of the bias term\n",
    "        yield 0\n",
    "        # then yield the normal indices\n",
    "        for index in x:\n",
    "            yield index\n",
    "\n",
    "        # now yield interactions (if applicable)\n",
    "        if self.interaction:\n",
    "            D = self.D\n",
    "            L = len(x)\n",
    "\n",
    "            x = sorted(x)\n",
    "            for i in xrange(L):\n",
    "                for j in xrange(i+1, L):\n",
    "                    # one-hot encode interactions with hash trick\n",
    "                    yield abs(hash(str(x[i]) + '_' + str(x[j]))) % D\n",
    "\n",
    "    def predict(self, x):\n",
    "        ''' Get probability estimation on x\n",
    "            INPUT: x: features\n",
    "            OUTPUT: probability of p(y = 1 | x; w)\n",
    "        '''\n",
    "        # parameters\n",
    "        alpha = self.alpha;beta = self.beta\n",
    "        L1 = self.L1;L2 = self.L2\n",
    "        # model\n",
    "        n = self.n;z = self.z;w = {}\n",
    "        # wTx is the inner product of w and x\n",
    "        \n",
    "        wTx = 0.\n",
    "        for i in self._indices(x): #先return一個0,再把x的index一個一個放到i\n",
    "            sign = -1. if z[i] < 0 else 1.  #z[x:varable index]\n",
    "\n",
    "            # build w on the fly using z and n, hence the name - lazy weights\n",
    "            # we are doing this at prediction instead of update time is because\n",
    "            # this allows us for not storing the complete w\n",
    "            \n",
    "            #權重過小，把w[i]設為0\n",
    "            if sign * z[i] <= L1:\n",
    "                # w[i] vanishes due to L1 regularization\n",
    "                w[i] = 0.\n",
    "            else:\n",
    "                # apply prediction time L1, L2 regularization to z and get w\n",
    "                w[i] = (sign * L1 - z[i]) / ((beta + sqrt(n[i])) / alpha + L2)\n",
    "\n",
    "            wTx += w[i]#得到wTx的加總值\n",
    "\n",
    "        # cache the current w for update stage\n",
    "        self.w = w\n",
    "        \n",
    "        # Return一個有上界的sigmoid function\n",
    "        # bounded sigmoid function, this is the probability estimation\n",
    "        return 1. / (1. + exp(-max(min(wTx, 35.), -35.)))\n",
    "\n",
    "    def update(self, x, p, y):\n",
    "        ''' Update model using x, p, y\n",
    "\n",
    "            INPUT:\n",
    "                x: feature, a list of indices\n",
    "                p: click probability prediction of our model\n",
    "                y: answer\n",
    "\n",
    "            MODIFIES:\n",
    "                self.n: increase by squared gradient\n",
    "                self.z: weights\n",
    "        '''\n",
    "\n",
    "        # parameter\n",
    "        alpha = self.alpha\n",
    "\n",
    "        # model\n",
    "        n = self.n\n",
    "        z = self.z\n",
    "        w = self.w\n",
    "\n",
    "        # gradient under logloss\n",
    "        g = p - y \n",
    "\n",
    "        # update z and n\n",
    "        for i in self._indices(x):\n",
    "            sigma = (sqrt(n[i] + g * g) - sqrt(n[i])) / alpha\n",
    "            z[i] += g - sigma * w[i]\n",
    "            n[i] += g * g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-jumping",
   "metadata": {},
   "source": [
    "### Define Logloss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "posted-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Done!\n",
    "def logloss(p, y):\n",
    "    ''' FUNCTION: Bounded logloss\n",
    "        INPUT:\n",
    "            p: our prediction\n",
    "            y: real answer\n",
    "        OUTPUT:\n",
    "            logarithmic loss of p given y\n",
    "    '''\n",
    "    p = max(min(p, 1. - 10e-15), 10e-15)\n",
    "    print(p)\n",
    "    if y == 1.: #p(y=1∣x)\n",
    "        return -log(p)  \n",
    "    else: #p(y=0∣x)\n",
    "        return -log(1. - p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-sponsorship",
   "metadata": {},
   "source": [
    "### Define Data Generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "higher-wrapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Done: Data_generator\n",
    "def data(path, D):\n",
    "    ''' GENERATOR: Apply hash-trick to the original csv row\n",
    "                   and for simplicity, we one-hot-encode everything\n",
    "        INPUT:\n",
    "            path: path to training or testing file\n",
    "            D: the max index that we can hash to\n",
    "        YIELDS:\n",
    "            ID: id of the instance, mainly useless\n",
    "            x: a list of hashed and one-hot-encoded 'indices'\n",
    "               we only need the index since all values are either 0 or 1\n",
    "            y: y = 1 if we have a click, else we have y = 0\n",
    "    '''\n",
    "    for t, row in enumerate(DictReader(open(path))):\n",
    "        # 當前display_id,ad_id\n",
    "        disp_id = int(row['display_id'])\n",
    "        ad_id = int(row['ad_id'])\n",
    "\n",
    "        # Y值\n",
    "        y = 0.\n",
    "        if 'clicked' in row:\n",
    "            if row['clicked'] == '1':\n",
    "                y = 1.\n",
    "            del row['clicked']\n",
    "        \n",
    "        #紀錄x的hash位置\n",
    "        #整除取餘數的概念是想hash多少維度\n",
    "        x = []\n",
    "        for key in row:\n",
    "            x.append(abs(hash(key + '_' + row[key])) % D)\n",
    "\n",
    "        #ad_id在各promoted_content(哪個商家、哪個檔期)下的變數\n",
    "        #prcont_dict[ad_id]:[document_id\tcampaign_id\tadvertiser_id]\n",
    "        row = prcont_dict.get(ad_id, [])\t\t\n",
    "        # build x\n",
    "        ad_doc_id = -1\n",
    "        for ind, val in enumerate(row):\n",
    "            if ind==0:\n",
    "                ad_doc_id = int(val)\n",
    "            x.append(abs(hash(prcont_header[ind] + '_' + val)) % D)#abs(hash(string(Variable_value))) % D\n",
    "\n",
    "        #display_id在各event(使用者行為：登入平台、觀看文章、地點)下的變數\n",
    "        #event_header[display_id]:\tuuid\tdocument_id\ttimestamp\tplatform\tgeo_location\n",
    "        row = event_dict.get(disp_id, [])\n",
    "        ## build x\n",
    "        disp_doc_id = -1\n",
    "        for ind, val in enumerate(row):\n",
    "            if ind==0:\n",
    "                uuid_val = val\n",
    "            if ind==1:\n",
    "                disp_doc_id = int(val)\n",
    "            x.append(abs(hash(event_header[ind] + '_' + val)) % D)#abs(hash(string(Variable_value))) % D\n",
    "\n",
    "        ## yield 第幾筆資料,disp_id, ad_id, \n",
    "        #hashvalue(x):list[display_id,ad_id,document_id,campaign_id,advertiser_id,\n",
    "        #                  uuid,\tdocument_id\ttimestamp\tplatform\tgeo_location], y\n",
    "        yield t, disp_id, ad_id, x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-exchange",
   "metadata": {},
   "source": [
    "## Let's start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "surgical-bracket",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "# initialize ourselves a learner\n",
    "learner = ftrl_proximal(alpha, beta, L1, L2, D, interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "incredible-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(epoch):\n",
    "    loss = 0.\n",
    "    count = 0\n",
    "    date = 0\n",
    "\n",
    "    for t, disp_id, ad_id, x, y in data(train, D):  # data is a generator\n",
    "        #    t: just a instance counter\n",
    "        # date: you know what this is\n",
    "        #   ID: id provided in original data\n",
    "        #    x: features\n",
    "        #    y: label (click)\n",
    "\n",
    "        # step 1, get prediction from learner\n",
    "        p = learner.predict(x)\n",
    "\n",
    "        if (holdafter and date > holdafter) or (holdout and t % holdout == 0):\n",
    "            # step 2-1, calculate validation loss\n",
    "            #           we do not train with the validation data so that our\n",
    "            #           validation loss is an accurate estimation\n",
    "            #\n",
    "            # holdafter: train instances from day 1 to day N\n",
    "            #            validate with instances from day N + 1 and after\n",
    "            #\n",
    "            # holdout: validate with every N instance, train with others\n",
    "            loss += logloss(p, y)\n",
    "            count += 1\n",
    "        else:\n",
    "            # step 2-2, update learner with label (click) information\n",
    "            learner.update(x, p, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-volleyball",
   "metadata": {},
   "source": [
    "## Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "center-treaty",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(submission, 'w') as outfile:\n",
    "    outfile.write('display_id,ad_id,clicked\\n')\n",
    "    for t, disp_id, ad_id, x, y in data(test, D):\n",
    "        p = learner.predict(x)\n",
    "        outfile.write('%s,%s,%s\\n' % (disp_id, ad_id, str(p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-newcastle",
   "metadata": {},
   "source": [
    "## Transform to submit format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "downtown-vacation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "t = pd.read_csv(data_path+'sub_proba.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-bracket",
   "metadata": {},
   "source": [
    "得到test data FTRL預測機率值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "loose-venture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>display_id</th>\n",
       "      <th>ad_id</th>\n",
       "      <th>clicked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16874594</td>\n",
       "      <td>66758</td>\n",
       "      <td>0.052451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16874594</td>\n",
       "      <td>150083</td>\n",
       "      <td>0.086925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16874594</td>\n",
       "      <td>162754</td>\n",
       "      <td>0.203556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   display_id   ad_id   clicked\n",
       "0    16874594   66758  0.052451\n",
       "1    16874594  150083  0.086925\n",
       "2    16874594  162754  0.203556"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "posted-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.sort_values(['display_id','clicked'], inplace=True, ascending=False)\n",
    "subi = t.groupby('display_id').ad_id.apply(lambda x: \" \".join(map(str,x))).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "tribal-freeware",
   "metadata": {},
   "outputs": [],
   "source": [
    "del t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "matched-dodge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6245533"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "north-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "subi.to_csv(data_path+'sub_format_FTRL.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
